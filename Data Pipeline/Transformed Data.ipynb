{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da8e30b-43ce-4a5a-a088-d776e90c9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def mm_getter(file_path, df_name):\n",
    "    # Getting the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    team = pd.read_csv(file_path)\n",
    "\n",
    "    # Select important columns\n",
    "    info = team[[\"Team\", \"Levels\", \"Champion\", \"Year\"]]\n",
    "\n",
    "    # Drop unimportant columns\n",
    "    team = team.drop(columns=[\"Rk\", \"G\", \"MPA\", \"Opp.MPA\", \"MP\", \"HeavesA\", \"Heaves\", \"Opp.MP\", \"Team\", \"Levels\", \"Champion\", \"Year\"])\n",
    "\n",
    "    # Apply Min-Max scaling\n",
    "    X = pd.DataFrame(scaler.fit_transform(team), columns=team.columns)\n",
    "\n",
    "    # Combine the scaled data with the info DataFrame\n",
    "    df_name = pd.concat([info, X], axis=1)\n",
    "    \n",
    "    return df_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740f9fef-f279-4e60-bef5-966a57dc6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "def percentile_getter(file_path, df_name):\n",
    "    # Getting the scaler\n",
    "    scaler = QuantileTransformer(n_quantiles=30, output_distribution='uniform')\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    team = pd.read_csv(file_path)\n",
    "\n",
    "    # Select important columns\n",
    "    info = team[[\"Team\", \"Levels\", \"Champion\", \"Year\"]]\n",
    "\n",
    "    # Drop unimportant columns\n",
    "    team = team.drop(columns=[\"Rk\", \"G\", \"MPA\", \"Opp.MPA\", \"MP\", \"HeavesA\", \"Heaves\", \"Opp.MP\", \"Team\", \"Levels\", \"Champion\", \"Year\"])\n",
    "\n",
    "    # Apply Min-Max scaling\n",
    "    X = pd.DataFrame(scaler.fit_transform(team), columns=team.columns)\n",
    "\n",
    "    # Combine the scaled data with the info DataFrame\n",
    "    df_name = pd.concat([info, X], axis=1)\n",
    "    \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b7f3517-b91a-4a4f-b57d-e1f2ccc7d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of all the years (last two digits of each year)\n",
    "years = list(range(2009, 2025))  # 2009-2010 to 2024-2025 seasons\n",
    "\n",
    "# Create file paths using the last two digits of the year for each season\n",
    "file_paths = [f\"C:/Users/hagen/Downloads/NBA DATA/Teams/Cleaned Yearly Data/{str(year)[2:]}-{str(year+1)[2:]} Team Data.csv\" for year in years]\n",
    "\n",
    "# List to store the processed data for each year\n",
    "processed_data = []\n",
    "\n",
    "# Loop through each year and process the corresponding file\n",
    "for year, file_path in zip(years, file_paths):\n",
    "    # Apply the mm_getter function for each year\n",
    "    df = mm_getter(file_path, f\"mm_data_{year}\")\n",
    "    \n",
    "    # Append the processed DataFrame to the list\n",
    "    processed_data.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list by row (axis=0)\n",
    "all_team_data_mm = pd.concat(processed_data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b086838-22f1-4bc7-ae01-15bb5da09be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of all the years (last two digits of each year)\n",
    "years = list(range(2009, 2025))  # 2009-2010 to 2024-2025 seasons\n",
    "\n",
    "# Create file paths using the last two digits of the year for each season\n",
    "file_paths = [f\"C:/Users/hagen/Downloads/NBA DATA/Teams/Cleaned Yearly Data/{str(year)[2:]}-{str(year+1)[2:]} Team Data.csv\" for year in years]\n",
    "\n",
    "# List to store the processed data for each year\n",
    "processed_data = []\n",
    "\n",
    "# Loop through each year and process the corresponding file\n",
    "for year, file_path in zip(years, file_paths):\n",
    "    # Apply the mm_getter function for each year\n",
    "    df = percentile_getter(file_path, f\"mm_data_{year}\")\n",
    "    \n",
    "    # Append the processed DataFrame to the list\n",
    "    processed_data.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list by row (axis=0)\n",
    "all_team_data_p = pd.concat(processed_data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ded7b7-9975-45f0-8afd-2d0c172a0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_team_data_mm.to_csv(\"C:/Users/hagen/Downloads/NBA DATA/Teams/Transformed Data/mm_data.csv\", index=False)\n",
    "\n",
    "all_team_data_p.to_csv(\"C:/Users/hagen/Downloads/NBA DATA/Teams/Transformed Data/p_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b07add-c45c-49fc-ac5b-52e59f1a31d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
